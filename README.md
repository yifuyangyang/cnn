1.网络结构参数对模型精度的影响
2.通过手动调参提升模型性能的方法
3.CNN 相比 MLP 在图像分类任务中的优势

4.在代码顶部 CONFIG 中选择模型：
"model": "mlp"   # 或 "cnn"


5.BP 神经网络（MLP）：通过调参，使 测试集准确率达到 98% 及以上

6.卷积神经网络（CNN）：通过调参，使 测试集准确率达到 99% 及以上

7.训练参数调整（可选）
可在 CONFIG 中修改：
学习率 lr
训练轮数 epochs
批大小 batch_size

8.作业提交内容（必须上传）

请提交以下内容：

（1）实验代码
修改后的 cnn.py

（2）结果截图或图片
MLP 达到 ≥98% 准确率的运行结果截图
CNN 达到 ≥99% 准确率的运行结果截图

（3）对应的训练曲线图（results.png，可多张）

（4）实验说明
简要说明所采用的网络结构和最终准确率
可写在 README.md 末尾或单独提交文档

9.最终提交PR时，请将标题修改为：学号+姓名，1979801234张三

mlp的网络结构
输入层: 784维向量（28×28图像展平）
隐藏层1: 512个神经元 → ReLU激活 → Dropout(30%)
隐藏层2: 256个神经元 → ReLU激活 → Dropout(30%)
隐藏层3: 128个神经元 → ReLU激活 → Dropout(30%)
输出层: 10个神经元（10个数字类别）
"epochs": 25,"batch_size": 128,"lr": 1e-3, "optimizer": "adam",
最终准确率是98.51%

cnn的网络结构
卷积部分
第一层卷积：32个3×3卷积核，输入1通道→输出32通道
输出尺寸：28×28 → 28×28（保持，因为有padding=1）
ReLU激活 → 2×2最大池化 → 14×14
第二层卷积：64个3×3卷积核，输入32通道→输出64通道
输出尺寸：14×14 → 14×14
ReLU激活 → 2×2最大池化 → 7×7

全连接部分
Flatten展开：64×7×7 = 3136维特征向量
第一全连接层：3136 → 256神经元 + ReLU
第二全连接层：256 → 128神经元
输出层：128 → 10神经元（10个数字类别）
"epochs": 10,"batch_size": 64,"lr": 1e-3, "optimizer": "adam",    
最终准确率是99.21%