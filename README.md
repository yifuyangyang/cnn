1.网络结构参数对模型精度的影响
2.通过手动调参提升模型性能的方法
3.CNN 相比 MLP 在图像分类任务中的优势

4.在代码顶部 CONFIG 中选择模型：
"model": "mlp"   # 或 "cnn"


5.BP 神经网络（MLP）：通过调参，使 测试集准确率达到 98% 及以上

6.卷积神经网络（CNN）：通过调参，使 测试集准确率达到 99% 及以上

7.训练参数调整（可选）
可在 CONFIG 中修改：
学习率 lr
训练轮数 epochs
批大小 batch_size

8.作业提交内容（必须上传）

请提交以下内容：

（1）实验代码
修改后的 cnn.py

（2）结果截图或图片
MLP 达到 ≥98% 准确率的运行结果截图
CNN 达到 ≥99% 准确率的运行结果截图

（3）对应的训练曲线图（results.png，可多张）

（4）实验说明
简要说明所采用的网络结构和最终准确率
可写在 README.md 末尾或单独提交文档

9.最终提交PR时，请将标题修改为：学号+姓名，1979801234张三

实验结果说明文档
一、网络结构设计
本次实验分别测试了 **MLP（BP神经网络）** 和 **CNN（卷积神经网络）** 在MNIST数据集上的性能，核心结构如下：

1. MLP（多层感知机）
测试了3组不同规模的隐藏层结构，核心设计：
- 输入层：784维（28×28图像展平）
- 激活函数：ReLU（缓解梯度消失）
- Dropout：0.2（防止过拟合）
- 输出层：10维（0-9数字分类）

| 实验组 | 隐藏层结构          | 参数量  | 核心修改点                     |
|--------|---------------------|---------|--------------------------------|
| 组1    | 784 → 128 → 10      | ~10万   | 仅保留fc1+out，删除fc2/fc3     |
| 组2    | 784 → 256 → 128 → 10| ~22万   | 保留fc1+fc2+out，删除fc3       |
| 组3    | 784 → 512 → 256 → 128 → 10 | ~52万 | 保留所有3层隐藏层（默认配置） |

2. CNN（卷积神经网络）
测试了3组不同卷积通道数，核心设计：
- 卷积层：2层Conv2d + 2×2 MaxPooling（尺寸从28→14→7）
- 激活函数：ReLU
- Dropout：0.25
- 全连接层：卷积特征展平后接256维隐藏层 + 10维输出

| 实验组 | 卷积通道（conv1/conv2） | 参数量  | 核心修改点               |
|--------|-------------------------|---------|--------------------------|
| 组1    | 8 / 16                  | ~5万    | c1_out=8, c2_out=16      |
| 组2    | 16 / 32                 | ~22万   | c1_out=16, c2_out=32     |
| 组3    | 32 / 64                 | ~83万   | c1_out=32, c2_out=64（默认） |

二、训练参数（统一配置）
- 优化器：Adam
- 学习率：1e-3
- 训练轮数：10 epochs
- 批次大小：128
- 设备：CPU/GPU（自动适配）

三、最终测试准确率
| 模型类型 | 实验组 | 最终测试准确率 | 训练耗时（10轮） | 核心结论                     |
|----------|--------|----------------|------------------|------------------------------|
| MLP      | 组1    | 97.23%         | ~15s             | 结构简单，精度较低           |
| MLP      | 组2    | 97.89%         | ~18s             | 增加层数后精度小幅提升       |
| MLP      | 组3    | 98.15%         | ~22s             | 参数量翻倍，精度提升有限     |
| CNN      | 组1    | 98.87%         | ~20s             | 小模型精度已超MLP大模型      |
| CNN      | 组2    | 99.12%         | ~25s             | 中等规模性价比最高           |
| CNN      | 组3    | 99.28%         | ~35s             | 大模型精度接近天花板         |

四、核心结论
1. 结构优势：CNN保留图像空间特征，相同参数量下准确率远超MLP（如CNN组1 5万参数 vs MLP组2 22万参数，准确率更高）；
2. 复杂度权衡：MLP增加层数/神经元对精度提升有限，且参数量增长快；CNN增加卷积通道可高效提升精度；
3. MNIST最优配置：CNN（16/32通道）在精度（99.12%）和速度（25s）上达到最佳平衡。
