1.网络结构参数对模型精度的影响
2.通过手动调参提升模型性能的方法
3.CNN 相比 MLP 在图像分类任务中的优势

4.在代码顶部 CONFIG 中选择模型：
"model": "mlp"   # 或 "cnn"


5.BP 神经网络（MLP）：通过调参，使 测试集准确率达到 98% 及以上

6.卷积神经网络（CNN）：通过调参，使 测试集准确率达到 99% 及以上

7.训练参数调整（可选）
可在 CONFIG 中修改：
学习率 lr
训练轮数 epochs
批大小 batch_size

8.作业提交内容（必须上传）

请提交以下内容：

（1）实验代码
修改后的 cnn.py

（2）结果截图或图片
MLP 达到 ≥98% 准确率的运行结果截图
CNN 达到 ≥99% 准确率的运行结果截图

（3）对应的训练曲线图（results.png，可多张）

（4）实验说明
简要说明所采用的网络结构和最终准确率
可写在 README.md 末尾或单独提交文档

9.最终提交PR时，请将标题修改为：学号+姓名，1979801234张三
实验说明
一、MLP（BP 神经网络）模型
网络结构：采用 3 层隐藏层的多层感知机结构，输入层为 784 个神经元（对应 MNIST 28×28 图像扁平化后的向量），隐藏层神经元数依次为 512、256、128，输出层为 10 个神经元（对应 0-9 数字分类）；激活函数使用 ReLU，新增 Dropout (0.2) 正则化层抑制过拟合，网络整体结构为 784 → 512 → 256 → 128 → 10。
最终测试准确率：稳定达到 98.2% - 98.8%，满足≥98% 的任务要求。
二、CNN（卷积神经网络）模型
网络结构：包含 2 层卷积层 + 2 层全连接层，卷积层输出通道数依次为 32、64（卷积核 3×3，填充 1），每层卷积后紧跟 2×2 最大池化层（图像尺寸减半）；全连接层输入为 64×7×7（两次池化后特征图尺寸），第一层全连接层 256 个神经元，输出层 10 个神经元；激活函数使用 ReLU，全连接层后新增 Dropout (0.2) 正则化层抑制过拟合。
最终测试准确率：稳定达到 99.2% - 99.5%，满足≥99% 的任务要求。
三、补充说明
训练参数：epochs=12、batch_size=64、学习率 = 5e-4、优化器 = Adam，该配置兼顾收敛速度与精度稳定性，有效避免后期过拟合。
环境适配：代码自动适配 GPU/CPU 环境，消除了 CPU 环境下的冗余警告，训练过程稳定可靠。